{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Environment\n",
    "\n",
    "#### Please ensure that you have the following packages installed\n",
    "math; pandas; numpy; matplotlib; random; scipy; hmmlearn; sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_head import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Empirical Studies Section 4.3 - 4.5\n",
    "## Overall Parameter Setup\n",
    "The overall parameter choice is set in the $\\texttt{CVaR_parameter.py}$. Below are some of parameters selected in our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epsilon is the fixed parameter regarding optimizing CVaR, representing 1-\\eta\n",
    "epsilon = 0.05\n",
    "\n",
    "# for the whole rolling approach, the number of days we consider in each period\n",
    "## It is not just the physical days. Instead, in our paper, we consider the month as a unit. \n",
    "rolling_day = 1\n",
    "\n",
    "# It denotes whether we include the shortsale constraints in our optimization model\n",
    "## 0 represents that we incorporate the shortsale constraint: x_i >= 0 in our paper\n",
    "shortsale_sign = 0\n",
    "\n",
    "# cross validation choice\n",
    "## cv_type == -1 means no  \n",
    "## cv_type == 1 means gridsearch\n",
    "cv_type = 1\n",
    "\n",
    "# the K-fold number in cross validation\n",
    "fold_number = 4\n",
    "\n",
    "# the possible theta param corresponding to m in the paper) used in the cross validation\n",
    "theta_param = [0.02, 0.04, 0.06, 0.08, 0.1]\n",
    "\n",
    "# whether we take the risk-free rate into account in computing SR\n",
    "## true means we need to minus the risk-free rate from the dataset and false means not\n",
    "## Because DeMiguel's paper does not incorporate risk free rate, we do not incorporate that item too in the test statistics computation.\n",
    "sharpe_ratio_open = False\n",
    "\n",
    "#to make it more clearly, unit = 1 means the unit of portfolio dta is x%, unit = 100 means the unit of portfolio dta is x. \n",
    "unit = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Specific Data Set Choice\n",
    "Below are the parameters that fix the data sets in the $\\texttt{factor model}$ folder. We choose the concrete dataset in that folder. By changing those parameters, we can switch to different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the dataset name and the file path\n",
    "portfolio_number = 16\n",
    "freq = \"Monthly\"\n",
    "#Here as we all use the Monthly Data Set, we can fix that parameter\n",
    "\n",
    "value = \"\"\n",
    "#eq/not eq csv in the . Here we all use the original dataset class.\n",
    "\n",
    "#dta type\n",
    "## In DeMiguel's paper, the dta type are selected to be one in ['MKT', 'Country', 'S&P_sectors', 'IndustryPortfolios', 'FF']\n",
    "## When his dataset extended to 2019 Q1, the dta type are selected to be one in ['MKT2', 'Country2', 'S&P_sectors2', 'IndustryPortfolios2', 'FF22']\n",
    "## Their corresponding portfolio number is 3, 9, 11, 11, 21(24)\n",
    "## And in our case study, dta type are selected to be 'IndustryIndices' (16)\n",
    "data_type = \"IndustryIndices\"\n",
    "\n",
    "#select part of the data in the .csv file.\n",
    "## from start_time to train_test_split as the default train dataset; from train_test_split (not include) as the test dataset.\n",
    "start_time = 20040101\n",
    "end_time = 201905\n",
    "train_test_split = 20061231"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "we load the return data and its corresponding factor data below using the class from $\\texttt{data_process/input.py}$.\n",
    "\n",
    "Note that the expressions for the model are explicitly written in the paper. We apply a rolling-sample approach with window size to be $M$. For the overall $T$ monthly-long data, in each month $t$, we use the dataset from months $t$ to $t + M - 1$ as input to solve the portfolio optimization problem. Then, we obtain the portfolio weights by solving the optimization problem for month $t + M$, where optimized weights $x_{i}^*$ are used to compute the returns $t + M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data input\n",
    "Input_csv = Input(portfolio_number, freq, value, start_time, end_time, train_test_split, data_type)\n",
    "[data_head, data_parameter, csv_name] = Input_csv.parameter_output()\n",
    "[df_select, df_train] = Input_csv.data_load()\n",
    "\n",
    "df_factor = Input_csv.three_factor_load()\n",
    "#we do not include the risk free rate item into the computation of sharpe ratio\n",
    "if sharpe_ratio_open == False:\n",
    "    rfr_data = 0\n",
    "else:\n",
    "    rfr_data = Input_csv.risk_free_rate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation \n",
    "To evaluate the performance of each model, we compute the following return statistics similar to what have done in DeMiguel et al. (2009b).The return statistics are computed in $\\texttt{data_process/test_result.py}$ and the turnover metric is computed in each model. We refer the output information to the $\\texttt{result_hmm/xx.csv}$.\n",
    "## Output Return Statistics Computation & Comparison\n",
    "### Sharpe ratio\n",
    "We denote the out-of-sample Sharpe ratio as the sample mean of the out-of-sample excess return $\\hat{\\mu}$ over the risk-free asset, then divided by their sample standard deviation, $\\hat{\\sigma}$:\n",
    "$$\\text{Sharpe ratio} = \\frac{\\hat{\\mu}}{\\hat{\\sigma}}$$\n",
    "### CEQ\n",
    "We measure the certainty equivalent (CEQ) return, defined as the risk-free rate that an investor is willing to take compared to a specific model.\n",
    "$$\\text{CEQ} = \\hat{\\mu} - \\frac{1}{2}\\hat{\\sigma}^2.$$\n",
    "### drawdown\n",
    "(Maximum) drawdown can be extracted from the formula: $-\\min\\{\\boldsymbol r_{M + 1},\\boldsymbol r_{M + 2},...,\\boldsymbol r_T \\}.$\n",
    "### turnover\n",
    "This is computed by the average of the $\\ell_1$ norm of the trades across the $N$ risky assets:\n",
    "$$\\text{Turnover} = \\frac{1}{T - M}\\sum_{t = 1}^{T - M}\\|\\boldsymbol x_{t + 1}^* - \\boldsymbol x_{t_+}\\|_1,$$\n",
    "where $\\boldsymbol x_{t+1}^*$ is the optimal portfolio weight vector at time $t + 1$ and $\\boldsymbol x_{t_+}$ is th portfolio weight right before rebalancing at time $t + 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#initiation for the test metric module\n",
    "#print the output into a separate csv file, separated by the dataset type + header\n",
    "Output_csv = output(csv_name, data_head, data_parameter)\n",
    "Output_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Strategies\n",
    "$\\texttt{method.rolling(shortsale)}$ represents the rolling-sample approach for each model.\n",
    "### Equally Weighted Portfolio\n",
    "This equally weighted strategy means that we consider the portfolio weight to be as follows for each of the $I$ risky assets:\n",
    "$$w_i = \\frac{1}{I},$$\n",
    "which gains popularity for its robustness in DeMiguel et al. (2009b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184 36\n",
      "For the model with strategy name  EW portfolio\n",
      "The Monthly Sharpe Ratio =  0.10897235636499304\n",
      "CEQ =  0.002903016286052641\n",
      "Drawdown =  0.17844068775\n",
      "Turnover =  0.037593675961054306\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "# EW Portfolio\n",
    "naive = naive_strategy(df_select, df_train, rolling_day, portfolio_number, \"EW portfolio\")\n",
    "naive.rolling()\n",
    "Output_csv.return_info(naive, rfr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following model requires the information of history returns $\\{\\boldsymbol{r}_1, \\boldsymbol{r}_2,...,\\boldsymbol{r}_M\\}$.\n",
    "## CVaR\n",
    "The optimization problem for the $\\texttt{CVaR}$ metric is computed below:\n",
    "$$\\min_{\\boldsymbol x \\in \\mathcal{X}, v \\in \\mathbb{R}}\\left\\{v+\\frac{1}{1-\\eta} \\frac{1}{M}\\sum\\limits_{i \\in[M]}\\left(-\\boldsymbol r_{i}^{\\prime} \\boldsymbol x-v\\right)^{+}\\right\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the model with strategy name  CVaR\n",
      "The Monthly Sharpe Ratio =  0.013843392144446654\n",
      "CEQ =  6.174958883421348e-05\n",
      "Drawdown =  0.11351946172396145\n",
      "Turnover =  0.16242807201509424\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "# SAA-CVaR model\n",
    "saa_CVaR = SAA_CVaR(df_select, df_train, rolling_day, portfolio_number, 'CVaR')\n",
    "train_return = saa_CVaR.rolling()  \n",
    "Output_csv.return_info(saa_CVaR, rfr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DR CVaR (Wasserstein)\n",
    "Common ways to illustrate the Wasserstein ambiguity set:\n",
    "$$F_{W}(\\theta)=\\left\\{\\mathbb{P} \\in \\mathcal{P}\\left(\\mathbb{R}^{I}\\right) ~\\left\\vert~ \\begin{array}{ll}{\\tilde{\\boldsymbol r} \\sim \\mathbb{P}}\\\\ {\\hat{\\mathbb{P}}_M:=\\frac{1}{M}\\sum_{n = 1}^{M}\\delta_{\\boldsymbol r_{n}}}\\\\{P(W_p(\\mathbb{P},\\hat{\\mathbb{P}}_M) \\leq \\theta) = 1}\\end{array}\\right.\\right\\}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the model with strategy name  DR CVaR (Wasserstein)\n",
      "The Monthly Sharpe Ratio =  0.10809414899889463\n",
      "CEQ =  0.002631628265429075\n",
      "Drawdown =  0.1680567336\n",
      "Turnover =  0.1924298093644551\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "method_name = \"DR CVaR (Wasserstein)\"\n",
    "mean_constr = False\n",
    "fcvar_wasserstein2 = FCVaR_wasserstein2(df_select, df_train, rolling_day, portfolio_number, 1, method_name, cv_type, mean_constr)\n",
    "fcvar_wasserstein2.rolling()\n",
    "Output_csv.return_info(fcvar_wasserstein2, rfr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incoporate the Mean Constraint\n",
    "### How to incorporate the mean constraint:\n",
    "For a traditionally problem, the mean constraint refers to: $\\boldsymbol \\mu^{\\prime}\\boldsymbol x \\geq R.$ \n",
    "\n",
    "In the distributionally robust version, we incorporate the following mean constraint:\n",
    "$$\\inf_{\\mathbb{P} \\in F} \\mathbb{E}_{\\mathbb{P}}[\\boldsymbol r^{\\prime}\\boldsymbol x]\\geq R.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Proposed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#whether to incorporate the worst-case mean constraint\n",
    "mean_sign = ''\n",
    "\n",
    "#choice_index = 0 --> Bull & Bear;\n",
    "#choice_index = 1 --> Weathers\n",
    "#choice_index = 2 --> HMM\n",
    "choice_index = 2\n",
    "hmm_type = -1\n",
    "\n",
    "if mean_sign == \"\":\n",
    "    mean_constr = False\n",
    "else:\n",
    "    mean_constr = 'worst-case'\n",
    "\n",
    "cls_num_choice = [2, 4, 4]\n",
    "state_choice = ['BB', 'weathers', 'HMM']\n",
    "method_choice = ['(Bull & Bear)', '(Weathers)', '(HMM)']    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained for determining the Markovian States\n",
    "We use the MATLAB hmmtrain function for training the HMM model.\n",
    "\n",
    "And we use the difference between predicted GDP (CPI) and true GDP (CPI)to classify into 2 states.\n",
    "\n",
    "And Bull & Bear state results are saved in $\\texttt{factor model/BB_state.csv}$;\n",
    "\n",
    "Weathers results are saved in $\\texttt{factor model/weathers_state.csv}$;\n",
    "\n",
    "HMM results are saved in $\\texttt{factor model/HMM_state.csv}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regime Determination\n",
    "We would first load the HMM / Weathers / Bull & Bear Classification result within the right train test time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrain for Heterogeneous I\n",
    "cluster_num = cls_num_choice[choice_index]\n",
    "df_state_case = pd.read_csv('../factor model/' + state_choice[choice_index] + '_state.csv')\n",
    "str_state = [str(each_state) for each_state in list(df_state_case['Date'])]\n",
    "df_state_case['Date'] = str_state\n",
    "mkt_state = df_state_case[((df_state_case['Date'])>=str(start_time))&(df_state_case['Date']<str(end_time))]['state']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RS CVaR Model\n",
    "i.e. our proposed model with $\\theta = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_name = 'RS ' + mean_sign + 'CVaR ' + method_choice[choice_index]\n",
    "cv_type = -1\n",
    "mean_cvar_mkt = FCVaR_HMM_wasserstein(df_select, df_train, rolling_day, portfolio_number, df_factor, cluster_num, method_name, mkt_state, hmm_type, cv_type, mean_constr)\n",
    "mean_cvar_mkt.theta = 0\n",
    "mean_cvar_mkt.rolling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the model with strategy name  RS CVaR (HMM)\n",
      "The Monthly Sharpe Ratio =  0.07700170662163114\n",
      "CEQ =  0.0015196528867957816\n",
      "Drawdown =  0.11351946172396143\n",
      "Turnover =  0.5811725525480759\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "Output_csv.return_info(mean_cvar_mkt, rfr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our RSDR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSDR CVaR (HMM)\n",
    "cv_type = 1\n",
    "method_name = 'RSDR ' + mean_sign + 'CVaR ' + method_choice[choice_index]\n",
    "mean_fcvar_mkt = FCVaR_HMM_wasserstein(df_select, df_train, rolling_day, portfolio_number, df_factor, cluster_num, method_name, mkt_state, hmm_type, cv_type, mean_constr)\n",
    "mean_fcvar_mkt.rolling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the model with strategy name  RSDR CVaR (HMM)\n",
      "The Monthly Sharpe Ratio =  0.1372613590794955\n",
      "CEQ =  0.0034765488401947626\n",
      "Drawdown =  0.1680567336\n",
      "Turnover =  0.2489523376563877\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "#return statistics computation for our policy\n",
    "Output_csv.return_info(mean_fcvar_mkt, rfr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
